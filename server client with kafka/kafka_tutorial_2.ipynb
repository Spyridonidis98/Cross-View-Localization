{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics: ['3DOF', '3DOF_start_producing_data']\n"
     ]
    }
   ],
   "source": [
    "# download kafka in a cloud server \n",
    "# in the config/server.properties file in line 35 add \n",
    "\n",
    "# listeners = PLAINTEXT://0.0.0.0:9092\n",
    "# listener.security.protocol.map=PLAINTEXT:PLAINTEXT\n",
    "# advertised.listeners = PLAINTEXT://host_public_ip:host_external_port_that_maps_to_9092_internaly\n",
    "# example\n",
    "# listeners=PLAINTEXT://0.0.0.0:9092\n",
    "# listener.security.protocol.map=PLAINTEXT:PLAINTEXT\n",
    "# advertised.listeners=PLAINTEXT://204.15.42.29:48471\n",
    "\n",
    "# listener name can be anything \n",
    "# if the port 9092 is not exposed in the server the connection will not work\n",
    "\n",
    "\n",
    "\n",
    "from kafka import KafkaAdminClient\n",
    "from kafka.admin import NewTopic\n",
    "\n",
    "bootstrap_servers = '38.80.153.61:31759'\n",
    "\n",
    "# Create an instance of KafkaAdminClient\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=[bootstrap_servers],  # Update with your Kafka broker(s)\n",
    "    client_id='0'\n",
    ")\n",
    "\n",
    "topic_name = 'my_first_topic'\n",
    "\n",
    "# num_partitions = 1\n",
    "# replication_factor = 1\n",
    "# my_first_topic = NewTopic(name=topic_name, num_partitions=num_partitions, replication_factor=replication_factor)\n",
    "\n",
    "# admin_client.create_topics(new_topics=[my_first_topic])\n",
    "\n",
    "# List all topics\n",
    "topics = admin_client.list_topics()\n",
    "print(\"Topics:\", topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'key': 'value0', 'key2': 'value0'}\n",
      "Sent: {'key': 'value1', 'key2': 'value1'}\n",
      "Sent: {'key': 'value2', 'key2': 'value2'}\n",
      "Sent: {'key': 'value3', 'key2': 'value3'}\n",
      "Sent: {'key': 'value4', 'key2': 'value4'}\n",
      "Sent: {'key': 'value5', 'key2': 'value5'}\n",
      "Sent: {'key': 'value6', 'key2': 'value6'}\n",
      "Sent: {'key': 'value7', 'key2': 'value7'}\n",
      "Sent: {'key': 'value8', 'key2': 'value8'}\n",
      "Sent: {'key': 'value9', 'key2': 'value9'}\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=[bootstrap_servers],\n",
    "                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "for i in range(10):\n",
    "    data = {f'key': f'value{i}', f'key2': f'value{i}'}\n",
    "    # send asyncronously with callbacks \n",
    "    producer.send(topic_name, value=data)# the data is sent to the topic, if the topic dosent exist it is created \n",
    "    print(f\"Sent: {data}\")\n",
    "\n",
    "# block until all async messages are sent \n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: {'key': 'value0', 'key2': 'value0'}\n",
      "Received: {'key': 'value1', 'key2': 'value1'}\n",
      "Received: {'key': 'value2', 'key2': 'value2'}\n",
      "Received: {'key': 'value0', 'key2': 'value0'}\n",
      "Received: {'key': 'value1', 'key2': 'value1'}\n",
      "Received: {'key': 'value2', 'key2': 'value2'}\n",
      "Received: {'key': 'value3', 'key2': 'value3'}\n",
      "Received: {'key': 'value4', 'key2': 'value4'}\n",
      "Received: {'key': 'value5', 'key2': 'value5'}\n",
      "Received: {'key': 'value6', 'key2': 'value6'}\n",
      "Received: {'key': 'value7', 'key2': 'value7'}\n",
      "Received: {'key': 'value8', 'key2': 'value8'}\n",
      "Received: {'key': 'value9', 'key2': 'value9'}\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "consumer = KafkaConsumer(topic_name,\n",
    "                         bootstrap_servers=[bootstrap_servers],\n",
    "                         auto_offset_reset='earliest', #stop consumer from waiting for messages after 1000ms\n",
    "                         value_deserializer = lambda x: json.loads(x.decode(\"utf-8\")),\n",
    "                          consumer_timeout_ms=1000 #stop consumer from waiting for messages after 1000ms \n",
    "                         )\n",
    "\n",
    "\n",
    "for message in consumer: #consumer will bring all events from the start end then wait for the next event to happend untill it time outs after 1000ms \n",
    "    print(f\"Received: {message.value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condapy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
