{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/home/dimitris/miniconda3/envs/condapy310/lib/python3.10/site-packages/charset_normalizer/constant.py)\n",
      "/mnt/c/Users/dimitris/Desktop/MyFiles/diplomatikh/pytorch-tensorflow/pytorch/Cross-View-Localization/server client with kafka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitris/miniconda3/envs/condapy310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dimitris/miniconda3/envs/condapy310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/dimitris/miniconda3/envs/condapy310/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3511, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import utils\n",
    "from Ford_dataset_s import SatGrdDatasetFordPresentation, train_logs, train_logs_img_inds, test_logs, test_logs_img_inds\n",
    "from models_ford_s import ModelFord\n",
    "from utils_s import render_point_cloud\n",
    "# from models_ford import ModelFord as ModelFord_orig\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np \n",
    "# from VGG import Unet, space2channel\n",
    "\n",
    "from train_ford_3DOF_s import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "# save_path ='ModelsFord/3DoF/Log_3lat20.0m_lon20.0m_rot10.0_Nit1_CrossAttn_FL_SL_3D_Uncertainty'\n",
    "save_path = 'Log_3lat20.0m_lon20.0m_rot10.0_Nit1_CrossAttn_FL_SL_3D_Uncertainty'\n",
    "args.train_log_start = 3\n",
    "\n",
    "# cameras = ['FL', 'SL'] \n",
    "# args.image_H = 256 #256\n",
    "# args.image_W = 1024#1024\n",
    "# args.cameras = cameras\n",
    "# args.batch_size = 1\n",
    "# args.lifting = '3D' #homography\n",
    "\n",
    "test_set = SatGrdDatasetFordPresentation(logs=test_logs[args.train_log_start:args.train_log_start+1],\n",
    "                                logs_img_inds=test_logs_img_inds[args.train_log_start:args.train_log_start+1],\n",
    "                                shift_range_lat=args.shift_range_lat, shift_range_lon=args.shift_range_lon,\n",
    "                                rotation_range=args.rotation_range, whole=args.test_whole, \n",
    "                                H = args.image_H, W = args.image_W, cameras=args.cameras, mode='train') \n",
    "# testloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=True,\n",
    "#                             num_workers=2, drop_last=False)\n",
    "\n",
    "device = 'cuda' #torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "args.Rs = {key:item.to(device) for key, item in test_set.Rs.items()}\n",
    "args.Ts = {key:item.to(device) for key, item in test_set.Ts.items()}\n",
    "args.Ks = {key:item.to(device) for key, item in test_set.Ks.items()}\n",
    "net = ModelFord(args).to(device)\n",
    "net.load_state_dict(torch.load(os.path.join(save_path, 'model_1.pth')), strict=False)\n",
    "\n",
    "len(test_set), args.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer,TopicPartition\n",
    "import msgpack\n",
    "import simplejpeg\n",
    "import torch\n",
    "topic_name = '3DOF'\n",
    "\n",
    "def dict_to_bytes(data_dict):\n",
    "    return msgpack.packb(data_dict, use_bin_type=True)\n",
    "\n",
    "\n",
    "def bytes_to_dict(json_str):\n",
    "    return msgpack.unpackb(json_str, raw=False)\n",
    "\n",
    "\n",
    "def encode_pytorch_image(img):\n",
    "    \"\"\"\n",
    "    Takes a pytorch tensor of shape (3,H,W) and encodes it to bytes, jpeg compression is used \n",
    "    img is float32 and values are in range (0,1)\n",
    "    \"\"\"\n",
    "    img_numpy = img * 255.0 \n",
    "    img_numpy = torch.permute(img_numpy, (1,2,0)).contiguous()\n",
    "    img_numpy = img_numpy.to(torch.uint8).numpy()\n",
    "    grd_img_bytes = simplejpeg.encode_jpeg(img_numpy)\n",
    "\n",
    "    return grd_img_bytes\n",
    "\n",
    "def decode_pytorch_image(img_bytes):\n",
    "    \"\"\"\n",
    "    Takes an encoded pytorch images that is in the form of bytes and decodes it \n",
    "    return tensor of shape (3,H,W)\n",
    "    \"\"\"\n",
    "    img_numpy = simplejpeg.decode_jpeg(img_bytes)\n",
    "    img_torch = torch.tensor(img_numpy, dtype=torch.float32) / 255.0\n",
    "    img_torch = torch.permute(img_torch, [2,0,1]).contiguous()\n",
    "\n",
    "    return img_torch\n",
    "\n",
    "bootstrap_servers=['localhost:9092']\n",
    "\n",
    "consumer = KafkaConsumer(#topic = topic_name,\n",
    "                         bootstrap_servers=bootstrap_servers,\n",
    "                         auto_offset_reset='latest', #will start consuming from the last message in the topic \n",
    "                         #consumer_timeout_ms=10000 #stop consumer from waiting for messages after 1000ms of not reciving any messages \n",
    "                         )\n",
    "\n",
    "tp1 = TopicPartition(topic_name, 1)\n",
    "consumer.assign([tp1])\n",
    "\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=bootstrap_servers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n",
      "data recived\n",
      "data send\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch.set_float32_matmul_precision('high') \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# net = torch.compile(net)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m consumer: \u001b[38;5;66;03m#consumer will bring all events from the start end then wait for the next event to happend untill it time outs after 1000ms \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata recived\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     data_recived \u001b[38;5;241m=\u001b[39m bytes_to_dict(message\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/consumer/group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/site-packages/kafka/client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m~/miniconda3/envs/condapy310/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.set_float32_matmul_precision('high') \n",
    "# net = torch.compile(net)\n",
    "\n",
    "for message in consumer: #consumer will bring all events from the start end then wait for the next event to happend untill it time outs after 1000ms \n",
    "    print('data recived')\n",
    "    data_recived = bytes_to_dict(message.value)\n",
    "    image_0_bytes = data_recived['image_0']; image_0_tensor = decode_pytorch_image(image_0_bytes).unsqueeze(0).to(device)\n",
    "    image_1_bytes = data_recived['image_1']; image_1_tensor = decode_pytorch_image(image_1_bytes).unsqueeze(0).to(device)\n",
    "    grd_imgs = [image_0_tensor, image_1_tensor]\n",
    "    data_id = data_recived['data_id']\n",
    "\n",
    "\n",
    "    data_local = test_set[data_id]\n",
    "    sat_img, _, gt_shift_u, gt_shift_v, gt_heading, grd_names, sat_img_norot_notran, s_lat, s_lon, g_lat, g_lon, yaw = [[camera.to(device).unsqueeze(0) if type(camera) == torch.Tensor else camera for camera in item] if type(item)== tuple else item.to(device).unsqueeze(0) if type(item) == torch.Tensor else item for item in data_local]\n",
    "\n",
    "    sat_img_norot_notran_bytes = encode_pytorch_image(sat_img_norot_notran.cpu().squeeze(0))\n",
    "    sat_img_bytes = encode_pytorch_image(sat_img.cpu().squeeze(0))\n",
    "    with torch.no_grad():\n",
    "        pred_u, pred_v, pred_orien = net.CrossAttn_rot_corr(sat_img, grd_imgs, gt_shift_u, gt_shift_v, gt_heading, mode='test')\n",
    "        \n",
    "        data = {'pred_u': pred_u.cpu().item(), 'pred_v': pred_v.cpu().item(), 'pred_orien': pred_orien.cpu().item(), \n",
    "                's_lat':s_lat.cpu().item(), 's_lon':s_lon.cpu().item(), 'g_lat':g_lat.cpu().item(), 'g_lon':g_lon.cpu().item(), 'yaw':yaw.cpu().item(),\n",
    "                'gt_shift_u':gt_shift_u.cpu().item(), 'gt_shift_v':gt_shift_v.cpu().item(), 'gt_heading':gt_heading.cpu().item(),\n",
    "                'sat_img':sat_img_bytes, 'sat_img_norot_notran':sat_img_norot_notran_bytes}\n",
    "        data_bytes_send = dict_to_bytes(data)\n",
    "        #send data back \n",
    "        producer.send(topic_name, value=data_bytes_send, partition=2)\n",
    "        print('data send')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condapy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
